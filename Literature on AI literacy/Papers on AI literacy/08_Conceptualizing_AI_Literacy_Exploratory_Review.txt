Computers and Education: Artificial Intelligence 2 (2021) 100041

Contents lists available at ScienceDirect

Computers and Education: Artificial Intelligence
journal homepage: www.sciencedirect.com/journal/computers-and-education-artificial-intelligence

Conceptualizing AI literacy: An exploratory review
Davy Tsz Kit Ng a, *, Jac Ka Lok Leung b, Samuel Kai Wah Chu a, Maggie Shen Qiao a
a
b

Faculty of Education, The University of Hong Kong, Pokfulam, Hong Kong
Center for Education Innovation, Hong Kong University of Science and Technology, Hong Kong

A R T I C L E I N F O

A B S T R A C T

Keywords:
AI literacy
AI learning and teaching
AI in education
AI ethics
AI literacy questionnaire

Artificial Intelligence (AI) has spread across industries (e.g., business, science, art, education) to enhance user
experience, improve work efficiency, and create many future job opportunities. However, public understanding
of AI technologies and how to define AI literacy is under-explored. This vision poses upcoming challenges for our
next generation to learn about AI. On this note, an exploratory review was conducted to conceptualize the newly
emerging concept “AI literacy”, in search for a sound theoretical foundation to define, teach and evaluate AI
literacy. Grounded in literature on 30 existing peer-reviewed articles, this review proposed four aspects (i.e.,
know and understand, use and apply, evaluate and create, and ethical issues) for fostering AI literacy based on
the adaptation of classic literacies. This study sheds light on the consolidated definition, teaching, and ethical
concerns on AI literacy, establishing the groundwork for future research such as competency development and
assessment criteria on AI literacy.

1. Introduction
Artificial intelligence (AI) was first defined as “the science and en­
gineering of making intelligent machines” in 1956 (McCarthy, 2007, p.
2). Throughout several decades of the 20th century, AI has evolved
progressively into intelligent machines and algorithms that can reason
and adapt based on sets of rules and environment which mimic human
intelligence (McCarthy, 2007). Wang (2019) broadened the definition of
AI which can perform cognitive tasks particularly learning and
problem-solving with the exciting technological innovations such as
machine learning, natural language processing and neural networks
(Zawacki-Richter, Marín, Bond, & Gouverneur, 2019).
Artificial intelligence will eventually affect many facets of human life
rather than merely computer industries and everyone should learn AI.
Currently, the use of AI has spread across industries (e.g., business,
science, art, education) to enhance user experience and improve effi­
ciency. Applications of AI exist in many parts of our everyday life (e.g.,
smart home appliances, smartphones, Google, Siri). Vast majority of the
public acknowledges the existence of AI services and devices, but seldom
do they know about the concepts and technology behind, or aware of
potential ethical issues related to AI (Burgsteiner, Kandlhofer, & Stein­
bauer, 2016; Ghallab, 2019). Although AI will generate significant
benefits for users, businesses and economies, and lift productivity and
economic growth, AI is poised to eliminate millions of current jobs and

cause declines in some occupations (Davenport & Ronanki, 2018;
Manyika et al., 2017).
Second, studies reflect that the rise of AI will create many job op­
portunities in various industries, and AI will probably replace tomor­
row’s workplace. Even though not all disciplines are not going to be
replaced by AI, people with AI knowledge will replace those that do not
in the future of work. In a MicKinsey report, Manyika et al. (2017)
estimated that 15% of the global working hours will be automated and
47% of American jobs are at high risk of automation by 2030.
Furthermore, the situation could be worse among women since over 160
million women worldwide may need to transition between occupations
often into higher-skilled roles. Among different natures of work, clerical
work such as secretaries and bookkeepers will be mostly easily elimi­
nated by AI, given that 72% of those jobs in advanced economies are
held by women (Manyika et al., 2017). As such, to gain a competitive
advantage at work, similar to classic literacy which includes reading/­
writing and mathematical abilities, AI literacy has emerged as a new
skill set that everyone should learn in response to this new era of
intelligence.
Literacy was popularly understood as an ability to read and write
(McBride, 2015). In today’s digital era, the emergence of the knowledgebased society implies that every citizen must be ‘digitally literate’ and
possess basic competencies in order to be on a better footing in terms of
equal opportunities in their workplaces (Bawden, 2008, p. 102). This

* Corresponding author.
E-mail addresses: davyngtk@connect.hku.hk (D.T.K. Ng), jac.leung@ust.hk (J.K.L. Leung), samchu@hku.hk (S.K.W. Chu), sqiao@connect.hku.hk (M.S. Qiao).
https://doi.org/10.1016/j.caeai.2021.100041
Received 12 July 2021; Received in revised form 12 November 2021; Accepted 12 November 2021
Available online 22 November 2021
2666-920X/© 2021 The Authors.
Published by Elsevier Ltd.
This is an open
(http://creativecommons.org/licenses/by-nc-nd/4.0/).

access

article

under

the

CC

BY-NC-ND

license

Computers and Education: Artificial Intelligence 2 (2021) 100041

D.T.K. Ng et al.

term has been extended to new literacies such as media, digital, infor­
mation, computer and AI literacy (Kong et al., 2021). In the twenty-first
century, students who are equipped with these skills could use related
technologies and computers in very advanced ways to learn new
knowledge and skills with their counterparts (Bell, 2010; Griffin & Care,
2014; Larson & Miller, 2011). Nowadays, AI technology emerges and
becomes essential skills to play critical roles across disciplines and in­
dustries (Ng et al., 2021; Touretzky et al., 2019). Students need to learn
how to use AI technologies judiciously, as well as to discriminate be­
tween ethical and unethical practices (Robinson, 2020; Rodrí­
guez-García, Moreno-León, Román-González, & Robles, 2020). AI
potentially becomes one of the important technology skills in the
twenty-first century. As such, to combine AI and literacy, AI literacy
means having the essential abilities that people need to live, learn and
work in our digital world through AI-driven technologies, and this
should be taught at the K-12 levels (Steinbauer et al., 2021).
AI learning started in university computer science education which
required advanced programming competencies that were not at an
appropriate level for K-12 learners. Educators faced challenges in scaf­
folding K-12 children to understand AI concepts through syntax-based
programming (e.g., McCarthy, 2007; Wong et al., 2020). The emer­
gence of more age-appropriate hardwares and softwares enabled edu­
cators to improve the learning process for younger learners in recent
years. The access to a wide range of technologies in day-to-day life, such
as chatbots and translation apps, presents opportunities for everyone to
understand and use AI in everyday life. This enables educators to
leverage on the availability of AI technologies to inculcate AI literacy for
young learners. For example, prior studies discussed the potential to
incorporate AI learning in K-12 STEAM education via playful experience
such as gamified and social media tools to prepare children for future
science, technology, engineering, art and mathematics workforces (e.g.,
Ng, 2021; Ng & Chu, 2021; Zou, Wang, & Zhao, 2019).
Knowing and using AI for future careers is only one aspect of
teaching AI literacy for educators. Any technology as potent as AI would
also bring new risks due to algorithmic bias and malicious uses of AI
(Brundage et al., 2018). People often overlook the importance of the
roles of AI ethics, which is considered as extraneous or surplus to
technical concerns in work settings (Hagendorff, 2020). Software de­
velopers usually feel a lack of accountability and moral significance of
their work, especially when economic incentives are easily overriding
commitment to ethical principles and values (Hagendorff, 2020). As
such, educating both citizens and computer scientists AI ethics is
essential to strengthen their social responsibility, and consider social
inclusion and diversity to apply AI for societal good (Dignum, 2019). In
this review, we examine the published studies to evaluate the ethical
concerns in the domain of AI literacy.
According to Google Scholar search, there is a dramatic increase in
AI literacy publications from 2014 to 2021 (see Fig. 1). As AI becomes
more and more important in work settings and everyday life, researchers

began to define AI literacy based on the term ‘literacy’ which has been
applied to define skill sets in varied disciplines (Long & Magerko, 2020).
However, few studies have provided comprehensive explanations on
how to conceptualize AI literacy. To achieve a better understanding of
the concept of AI literacy, we categorize how researchers define the term
in four aspects, inspired from the cognitive domains in Bloom’s taxon­
omy. Then, we evaluate how educators help learners develop AI literacy
skills with emerging technological tools, and evaluate their assessment
accordingly. To fill this gap, this study reviewed the relevant literature,
and analysed how scholars define “AI literacy”, how it can be learned,
and what are the ethical concerns. Specifically, the present study poses
the following four research questions:
1. How do researchers define the term “AI literacy”?
2. How do educators help learners develop AI literacy in terms of
learning artefacts, pedagogical approaches and subject matters?
3. How do researchers evaluate students’ AI literacy skills?
4. What are the ethical concerns in the domain of AI literacy?
2. Method
2.1. The search and manuscript selection process
As AI literacy is an emerging field in the twenty-first century, hence
available literature is limited. In search for literature on AI literacy, both
peer-reviewed scholarly articles and conference papers from K-12 to
higher education levels published from 2016 to 2021 through the Web of
Science, Scopus, ProQuest Education Collection, IEEE and ACM digital
library were included in this review. The first publication year found in
the databases was 2016. The aforementioned databases were considered
among the world’s most trusted citation indices platforms for evidencebased quality scientific research and hence helped us to ensure the in­
clusion of quality scientific content (Mongeon & Paul-Hus, 2016). The
articles that contained the phrase “AI literacy” OR “Artificial intelli­
gence literacy” in either the title, the abstract, main text or keywords
were downloaded and reviewed by the researchers. The search resulted
in 46 articles.
After excluding irrelevant studies, as of Apr 11, 2021, a total of 30
articles were identified. The articles were downloaded and reviewed by
our researchers during the document review. The selected articles then
were examined by two researchers to determine whether they were
suitable for the purpose of this study. During this examination, a set of
inclusion and exclusion criteria were adopted to ensure generalisation of
the findings and avoid biases in the studies selection (see Table 1). For
example, Sharma (2019) focused on the impact made by AI in entre­
preneurial activities including encouraging social innovation,
improving the institutional environment and gaining support from in­
ternational organizations, instead of integrating AI in educational
settings.

Table 1
Inclusion on and exclusion criteria.

Fig. 1. AI literacy articles from google scholar published by year.
2

Inclusion criteria

Exclusion criteria

(1) the studies had to review articles,
empirical papers, articles, case studies
or conference proceedings published
in the journals indexed by the
aforementioned databases.
(2) the studies had to be in the field of
education which was related to AI
literacy.
(3) the studies should provide
descriptions of the underlying theory
and methods.

(1) Editorials and books are excluded
due to the lack of peer review.
(2) Articles that mention the term “AI
literacy” are actually about how
AI is applying in particular fields
and unrelated to education.

D.T.K. Ng et al.

Computers and Education: Artificial Intelligence 2 (2021) 100041

2.2. The data coding and analysis processes

abovementioned databases were limited, it is observed that the
increasing trend of publications is consistent with Google Scholar’s
trend. In addition, we listed the nationality information of the first
author in the AI literacy paper and observed that many countries have
begun conceptualizing AI literacy. The regions that published two or
more AI literacy articles include: the United States (9), China (4), Hong
Kong (4), Spain (3) and Austria (3).
Researchers conducted studies and implemented AI literacy in­
terventions across various educational levels. Most of the articles
focused on primary school (14) and secondary school (14) students that
covered almost half of the reviewed studies. Only a few studies were
implemented for citizens (4), university students (4) and teachers (2).
Finally, some articles studied AI literacy in less conventional settings in
AI to bring up students for their future work, including libraries (1),
medicine (1) and meteorology (1). About one-third of the studies (9)
were conducted in an informal setting, which included after-school
programs, out-of-school activities and poster presentations. Seven
studies were conducted in regular lessons in a formal setting. The
remaining papers did not specify whether the settings are formal or
informal. One possible reason is that AI literacy is an emerging field, and
most researchers tend to conduct preliminary studies to explore their
interventions in an informal setting or merely write opinion papers
based on their observation.
Overall, there are 1 review paper, 4 conceptual articles and 25
empirical studies. Regarding the research method, most of the empirical
studies adopted qualitative (12) methods (see Table 3). Researchers used
quantitative methods (5) to assess students’ AI concepts, perceived
abilities and other constructs such as confidence in using AI and social
skills. Seven studies adopted a mixed-method approach (8) to collect
data via multiple data sources including ability tests, questionnaire
surveys, field notes, interviews and observations. We found one review
article (i.e., Long & Magerko, 2020) in which they searched broader
terms such as “AI education”, “learning about AI” and “AI school” to
map the key concepts underpinning AI literacy on their AI4K12 mailing
list and selected papers. Since AI literacy articles emerged these few
years, this review discusses how researchers use the specific term “AI
literacy” instead of teaching and learning AI.

This study began with formulating the study objectives, followed by
a review and analysis of AI literacy research trends according to the four
research questions. Then, the full text of the chosen articles was quali­
tatively classified using the constant comparative method espoused by
Glaser (1965), which was used in other recent systematic reviews (e.g.,
Hew & Cheung, 2014; Terras & Warwick, 2013). Through studying the
main content in the selected articles, similar meaningful concepts were
identified and extracted for further thematic analysis. Corresponding
text segments were coded under the coding schemes in each research
question. To establish coding reliability, six (30%) of the articles were
randomly picked, blind-coded and analysed by the two researchers. Two
experienced researchers then read and categorized the papers based on
the coding scheme. Disagreements were resolved through discussing the
disputed studies. Cohen’s kappa coefficient (0.9) was found to be
excellent to show inter-rater reliability between coders (Miles &
Huberman, 1994). After validating the coding scheme, the data findings
were then descriptively analysed and summarised in terms of frequency,
percentages and identified themes. In the case of discrepancy, the coders
resolved this and reached a final decision through discussion.
3. Results and discussion
In this section, background information (i.e., publication year,
country, levels of education and research method) of the 30 selected
studies is first described (see Table 2). Then, we present the results and
discuss these results according to the four research questions. The
publications of AI literacy papers increase from 2016 (2 articles) to 2019
(8 articles). Nineteen published articles were found between 2020 and
April 2021. Although the number of publications found in the
Table 2
Frequency (N, %) of the characteristics of the reviewed articles.
Variables

Categories

N

Percent

Year

2016
2018
2019
2020
2021
Austria
Belgium
China
Denmark
Hong Kong
India
Singapore
Spain
Sweden
Turkey
USA
UK
Research paper
Conceptual paper
Review paper
K-elementary
Secondary school
Higher education
Citizen
Teacher
AI-related agents
Hardware-focused artefacts
Software-focused artefacts
Unplugged artefacts
Formal
Informal
Not specified
Qualitative
Quantitative
Mixed research
Review articles/conceptual papers

2
1
8
17
2
3
1
4
1
4
1
1
3
1
1
9
1
25
4
1
14
14
4
4
2
11
8
6
7
7
9
14
12
5
8
5

6.7%
3.3%
26.7%
56.7%
6.7%
10.0%
3.3%
13.3%
3.3%
13.3%
3.3%
3.3%
10.0%
3.3%
3.3%
10.0%
3.3%
80.0%
13.3%
3.3%
46.7%
46.7%
13.3%
13.3%
6.7%
36.7%
26.7%
20.0%
23.3%
23.3%
30.0%
46.6%
40.0%
16.7%
26.7%
16.7%

Countries

Publication type
Educational level

Learning artefacts

Educational setting
Research methods

3.1. RQ 1. how do researchers define the term “AI literacy”?
Of the 30 articles, 17 articles defined AI literacy based on the ideas of
‘literacy’. Prior to AI literacy, the term “digital literacy” emerged to
assess basic computer-related concepts and skills when computer ap­
plications gained popularity across industries in the 1970s. It was
necessary for users to become competent in using computer systems
related to their specific task or job. The importance of digital literacy
increased as more people depend on the use of computer technologies to
develop new social and economic opportunities (Leahy & Dolan, 2010).
Table 3
Research methods.

3

Research
methods

N

Studies

Qualitative

12

Quantitative

5

Mixed method

8

Review articles

5

Burgsteiner et al. (2016); Han et al. (2018); How and Hung
(2019); Kaspersen et al. (2021); Leander and Burriss
(2020); Long et al. (2019); Rivero (2020); Robinson
(2020); Rodríguez-García et al. (2020); Schaper et al.
(2020); Vazhayil, Shetty, Bhavani, & Akshay (2019);
Watkins (2020).
Chai, Wang, and Xu (2020); Chai, Lin, et al. (2020); Dai
et al. (2020); Gong et al. (2020); Karaca (2020).
Druga et al. (2019); Julie et al. (2020); Kandlhofer et al.
(2016); Lin et al. (2021); Wan et al. (2020); Williams, Park,
& Breazeal (2019); Register & Ko (2020);
Rodríguez-García et al. (2020).
Long and Magerko (2020); Pegrum et al. (2018); Wong
et al. (2020); Xu (2020); Zou et al. (2019).

D.T.K. Ng et al.

Computers and Education: Artificial Intelligence 2 (2021) 100041

technological knowledge which then was applied in scientific
research-based learning to solve practical problems. Long et al. (2019)
engaged citizens in co-creating AI amenities in public spaces to broaden
their public AI literacy and experiences. Participants could engage with
public interactive artworks progress sequentially from being initially
attracted to an AI-enabled installation to relate their interaction with the
installation and other people.
Overall, although these articles showed slight variations on the
definition of AI literacy, they support the notion that everyone, espe­
cially K-12 children, acquire basic AI knowledge and abilities, enhance
motivation for future career, as well as use AI-enabled technology (Chai,
Lin, et al., 2020). In addition to knowing and using AI ethically, AI lit­
eracy serves as a set of competencies that enables individuals to criti­
cally evaluate AI technologies, communicate and collaborate effectively
with AI (Long & Magerko, 2020).

In succession to digital advancement, AI started to arise and imitate
human intelligence in machines for computers to learn, reason and
perceive. It was initially used in scientific research and academic envi­
ronments but had yet become ubiquitous in our daily lives. In summary,
four aspects of fostering AI literacy were identified from the review (see
Table 4).
3.2. Know and understand AI
Twenty-seven articles conceptualize AI literacy as educating learners
about acquiring fundamental concepts, skills, knowledge and attitudes
that require no prior knowledge. On top of being the end users of AI
applications, learners should understand the technologies behind.
Burgsteiner et al. (2016) and Kandlhofer et al. (2016) defined AI literacy
as the ability to understand the basic techniques and concepts behind AI
in different products and services. Moreover, some researchers associate
AI literacy with perceived abilities, confidence and readiness in learning
AI. In K-12 education, Druga et al. (2019) and Lin et al. (2021) designed
learning curriculums and activities that foster AI literacy that focuses on
how learners gain AI concepts.

3.5. Bloom’s taxonomy
Specifically, a definition for AI literacy learning is presented in the
aforementioned three aspects. In fact, the abilities and skills involved in
each aspect could be potentially mapped to the cognitive domains in
Bloom’s Taxonomy. Bloom’s Taxonomy is an approach to categorize the
levels of reasoning skills and ordered thinking required across different
learning contexts. There are six levels in the taxonomy, each requiring a
higher level of complexity and ordered thinking from the students. The
levels are understood to be successive, so that one level must be
mastered before the next level can be reached (Bloom, 1956; Huitt,
2011). The reason why we adopted the Bloom architecture is that AI
literacy is novice to educators and a classification of levels of cognitive
processes has not yet been developed in the context of AI learning.
However, this model is a classic pedagogical theory that establishes the
core foundation of AI taught to young learners. In our review, it is
proposed to assign these three aspects (i.e., know and understand, use,
and evaluate and create AI) into the cognitive levels of Bloom’s Tax­
onomy. “Know and understand AI” is assigned to the bottom two levels;
“use and apply AI” in applying concepts and applications is assigned to
the apply level; “evaluate and create AI” are assigned to the top three
levels to analyse, evaluate and create AI (see Fig. 2).
In our review, most studies discussed how to foster learners’ AI lit­
eracy in knowing and understanding AI (27), as well as how to use AI
applications in everyday life and apply its underlying concepts in
different contexts (30). Only 19 articles (63.3%) mentioned how to
enhance students to analyse, evaluate and create AI applications
through higher-order thinking activities. A possible reason that existing
AI literacy studies focused more on general skills and knowledge about
AI is that AI literacy is a set of fundamental skills and abilities in helping
everyone, including children and citizens, to acquire, construct and
apply knowledge. They may not necessarily handle how to abstract and
decompose AI problems, nor build AI applications; instead, they need to
know the basic concepts and use AI ethically. As such, most of our

3.3. Use and apply AI
All 30 articles emphasized the importance of educating learners to
know how to apply AI concepts in different contexts and applications in
everyday life. For example, Rodríguez-García et al. (2020) evaluated
LearningML, a machine learning model builder, to educate citizens to
understand AI applications and how it can affect our lives, as well as
knowing the ethical issues regarding AI technologies. In addition, half of
the studies (19) discussed the human-centered and ethical consider­
ations and focused on using AI concepts and application ethically, which
would be further discussed in RQ4. Eight articles borrowed the ideas of
computational thinking to interplay AI literacy and AI thinking (see
Table 5). AI thinking refers to the construction of logic and algorithms in
order to support students’ understanding of how to use knowledge bases
for problem-solving, processing semantics and handling unstructured
data (Vazhayil et al., 2019). For example, How and Hung (2019)
leveraged AI thinking through conducting data analytics with
computing, and interpreted new findings from the machine-learned
discovery of hidden patterns in data.
3.4. Evaluate and create AI
AI augments human intelligence with digital automation and 19
articles alluded AI literacy to engage learners in higher-order thinking
activities. Other than knowing and using AI with concepts and practices,
some studies had extended AI literacy to two other competencies that
enabled individuals to critically evaluate AI technologies, communicate
and collaborate effectively with AI (e.g., Long & Magerko, 2020). For
example, Han et al. (2018) enhanced students’ scientific and
Table 4
Coding framework of AI literacy.
AI literacy

Definitions

N

Sample references

Sample studies

Know &
understand
AI

Know the basic functions of AI and how
to use AI applications.

27

Lin et al. (2021)Lin et al. (2021);
Kandlhofer et al., 2016);
Robinson (2020).

Use & Apply AI

Applying AI knowledge, concepts and
applications in different scenarios.

30

Evaluate &
create AI

Higher-order thinking skills (e.g.,
evaluate, appraise, predict, design) with
AI applications.
Human-centered considerations (e.g.,
fairness, accountability, transparency,
ethics, safety).

19

Even though transparency in algorithms and AI in general has been
acknowledged to be ethically important, the public lacks understanding of
even the basic functions of AI. Efforts to make AI more comprehensible exist
(Robinson, 2020).
Apply k-means clustering in science contexts.. explore the mapping
relationship between facial features and data values and apply the concept to
brainstorm other objects such as Lego (Wan et al., 2020).
Design & build experiences: Technology exploration and creation activities
supported students in making sense of the underlying AI concepts. (Lee,
2020).
“AI for social good” measures an individual’s perception of the social
environment surrounding the behavior, which is related to subjective
norms (Chai et al., 2020).

AI ethics

19

4

Druga et al. (2019); Julie et al.
(2020); Vazhayil et al. (2019).
Druga et al. (2019); Han et al.
(2018); How and Hung (2019).
Chai et al. (2020); Druga et al.
(2019);
Gong et al. (2020).

D.T.K. Ng et al.

Computers and Education: Artificial Intelligence 2 (2021) 100041

Table 5
Interplay between AI and Brennan-Resnick’s (2012) computational thinking.
Elements

Descriptions

Examples

AI concepts
AI practices

Technical and conceptual understanding of the basic AI
concepts.
The techniques and strategies used when applying AI.

AI
perspectives

Attitudes and dispositions adopted while solving
problems.

● Understand the basic AI concepts and their origins such as machine learning, deep learning and
neural network.
● Appreciate the real-world applications of AI concepts such as speech recognition, robotics.
● Training, validation and testing.
● Remixing or reusing code.
● Collaborating to solve problems, understanding of technology as a problem-solving tool.
● Consider the ethical and safety concerns when applying AI technologies in real-world applications.

Fig. 2. Bloom’s Taxonomy and AI literacy.

Fig. 3. AI literacy TPACK framework.
5

D.T.K. Ng et al.

Computers and Education: Artificial Intelligence 2 (2021) 100041

selected AI literacy studies put more emphasis on engaging learners in
lower-level thinking activities. However, when students are promoted to
secondary schools and universities, they become knowledgeable to
apply their prior knowledge to create their own artefacts and justify
decisions with AI applications and algorithms.

Table 6
Learning artefacts.

3.6. RQ 2. how do educators help learners develop AI literacy in terms of
learning artefacts, pedagogical approaches and subject matters?
This review aims to fill recognized gaps in knowing the effective
means to integrate AI literacy into school curricula and how educators
help learners develop AI literacy. The elements found in our studies into
the Technological, Pedagogical and Content Knowledge (TPACK)
framework are categorized in terms of learning artefacts, pedagogical
approaches, and subject matters (see Fig. 3). The reason that we adopt
the TPACK model is that it is widely used across studies to identify how
teachers can incorporate technologies into their pedagogical methods
and content knowledge, and conceptualizes their capacity and knowl­
edge that is needed to integrate relevant technologies in AI literacy
education (e.g., Graham, 2011; Koehler et al., 2013). It provides a map
for understanding how to integrate AI literacy into classrooms effec­
tively. For example, Kim et al. (2021, pp. 1–13) based on AI learning
resources to conceptualize TPACK to improve teaching for K-12 AI ed­
ucation, which offers core foundations of AI taught to young learners.
Among the three knowledge, technological knowledge involves the
affordances and use of domain-specific learning tools such as hardware
and software in AI literacy education, AI-enabled tools (e.g., intelligent
agents), and unplugged learning tools (e.g., role-playing). Second,
pedagogical knowledge relates to teaching methods and their applica­
tion to promote student AI literacy learning, which entails teaching
strategies and scaffolding, feedbacking students’ learning processes
(Janssen et al., 2019). Third, content knowledge concerns knowledge
about the AI literacy subject matter that specific subjects should be
covered in the curriculum.
Learning artefacts: Given the complexity of AI, age-appropriate
learning artefacts were important to scaffold students’ AI conceptual
understandings and stimulate their motivation and interest in learning
AI. In recent years, there has been an increase in hardware and software
that enhance AI concepts accessible to younger learners. Table 6 pro­
vides an overview of the types of AI learning artefacts ranging from
hardware (8) to software-focused artefacts (6), intelligent agents (11)
and unplugged learning tools (5). The democratization of current AI
technologies encourages students to make intelligent agents and ma­
chine learning models without needing to program such as ML-for-kids
and Teachable Machine (Kaspersen et al., 2021; Long & Magerko, 2020).
In this context, we can see an opportunity for educators to democratize
access to AI literacy and reinforce the AI concepts through these
emerging tools. In addition, AI-driven tools such as chatbot, writing
assistants and web mapping encourage students to experience the soci­
etal impact and technological affordances of AI applications. Alterna­
tively, five studies designed unplugged learning activities to foster
students’ AI literacy without using a computer through engaging ap­
proaches such as case study, role-playing and storytelling (e.g., Julie
et al., 2020; Rodríguez-García et al., 2020). On the whole, most re­
searchers restricted the development of AI literacy skills within Com­
puter Science-related learning artefacts, while some researchers
extended AI literacy skills to non-CS elements such as role-playing and
storytelling.

Definition

Learning artefacts
examples

Sample studies

Hardwarefocused
artefacts

Use physical
artefacts to learn AI
such as robotics,
sensors and
Arduino devices.

Kandlhofer et al.
(2016)
Chai, Wang, and Xu
(2020)
Long et al. (2019)
Druga et al. (2019)
Burgsteiner et al.
(2016)

Softwarefocused
artefacts

Use digital
artefacts to learn AI
such as block/
syntax-based
programming and
simulation.

Bee-bots, LEGO
Mindstorms NXT,
Cubelets, alpha dog
robot, Kinect
LuminAI, VR Robot
Improv Circus,
Sound Happening,
Shape of Story
AI home assistants:
Jibo robot, Anki’s
Cozmo robot and
Amazon’s Alexa
Lego Mindstorms
NXT
Google maps,
Golog, YAGI,
ASRAEL
SmileyCluster, A*
algorithm in C#

AI-related
agents

Use intelligent
agents such as
expert systems,
machine learning
trainers, chatbots
to build their
custom machine
learning models
without coding.

Unplugged

Use learning
activities to learn
AI without a
computer such as
lecture, case study,
role-playing and
storytelling.

Scratch, Google’s
Teachable Machine,
Generative
Adversarial
Networks (GANS),
Watson AI services,
Bayesialab, AI home
assistants: Jibo
robot, Anki’s Cozmo
robot and Amazon’s
Alexa
Lectures, career
talk, textbook, case
study, webinar,
role-playing,
storytelling

Kandlhofer et al.
(2016)Wan, Zhou,
Ye, Mortensen, & Bai
(2020)
Burgsteiner et al.
(2016)
Lin et al. (2021)
Vazhayil et al. (2019)
How and Hung
(2019)
Druga et al. (2019)

Lin et al. (2021)
Dai et al. (2020)
Schaper et al. (2020)
Rodríguez-García
et al. (2020)
Julie et al. (2020)

example, researchers introduced children to AI concepts in playful and
inquiry approaches via high-order thinking activities such as creating
digital stories (Kandlhofer et al., 2016), performing Turing Test with
intelligent agents, creating chatbot and inference algorithms (Wong
et al., 2020), and building applications through blockly-based pro­
gramming (Gong et al., 2020). In addition to understanding the
connection between those AI techniques and common AI applications,
secondary school students should have the abilities to apply prior AI
knowledge in practical group projects to analyse and solve problems
independently (Kandlhofer et al., 2016). Thus, educators could design
real-world, collaborative projects based on the principles of con­
structionism and instructionism (Kandlhofer et al., 2016). Researchers
suggest various hands-on activities such as robot constructions (Wil­
liams et al., 2019), data and comparative visualization (Wan et al.,
2020), as well as training AI models (Vazhayli et al., 2019) as possible
means to promote AI literacy in secondary school levels.
Adult learners are categorized as university students and the general
public. Since university students have obtained fundamental AI under­
standing, they are more ready for further developments in this field.
They could conduct projects or research to describe problems formally
and on a higher abstraction level (Kandlhofer et al., 2016). As such, they
could apply AI skills and knowledge to solve real-world problems for
future academic and career challenges (Chat et al., 2020).
To cultivate the general public to understand and use AI applications
ethically, free online resources and courses (Robinson; 2020), public art
installations and museum exhibits (Rodríguez-García et al., 2020) are
viable approaches to establish a collaborative, creative, robust and safe
society.

3.7. Pedagogical approach
The pedagogies including teaching methods and strategies are clas­
sified according to the levels of education. One of the aims of AI literacy
education for primary schools is to familiarize children with the basic
concepts of AI/computer science and encourage them to discover the
connection between AI applications and the underlying concepts. For
6

D.T.K. Ng et al.

Computers and Education: Artificial Intelligence 2 (2021) 100041

teaching practice and management, and promote personalized learning
to understand students’ learning progress and needs (Xu, 2020). Xu
(2020) proposed the importance of learning AI for educators that
“teachers who know how to use AI may replace the teachers who do not
know how, because AI can empower teachers and promote their role
transformation which greatly improve the efficiency of management
and the level of decision-making” (p.290). In addition, teachers should
enable students to use AI-enhanced learning tools such as intelligent
tutors and adaptive learning systems to facilitate personalized learning
(e.g., self-diagnosing, providing automatic feedback and promoting
online collaboration among learners) (Cavalcanti et al., 2021).

3.8. Content knowledge
In K-12 education, studies that involved the design of learning
curricula and activities focus on how learners gain AI concepts, and how
they apply AI to contexts of their interests (e.g., Druga et al., 2019; Lin
et al., 2021). Long and Magerko (2020) and Rodríguez-García et al.
(2020) mentioned Touretzky et al. (2019)’s five “big ideas” of AI have
set a sound framework for future research on fostering AI literacy:
● Perceptions: Computers perceive the world using sensors.
● Representation and reasoning: Agents maintain representation of the
world and use them for reasoning.
● Learning: Computers can learn from data.
● Natural interaction: Intelligent agents require many kinds of
knowledge to interact naturally with humans.
● Societal impact: AI can impact society in both positive and negative
ways.

3.10. RQ 3. how do researchers evaluate students’ AI literacy skills?
Among 30 studies, researchers adopted quantitative (13) and quali­
tative (18) evaluation methods to examine how to assess students’
mastery and application of AI literacy-related skills (see Table 7), pro­
vided that we double-coded “mixed-method research” into quantitative
and qualitative evaluation methods. In addition, Robinson (2020) is not

Inspired by this framework, Wong et al. (2020) further categorized
AI literacy in K-12 into three dimensions: AI concepts, applications and
ethics. In another study, Rodríguez-García et al. (2020) evaluated
LearningML, a machine learning model builder, to develop critical
thinking. This model builder teaches K-12 students on AI fundamentals
to understand the applications of AI, how it can affect their lives, and the
ethical issues that arise from AI technologies.
In higher education, AI knowledge and skills become more advanced
to meet the future job demands. Kandlhofer et al. (2016) and Burgsteiner
et al. (2016) listed a set of AI concepts that have potential to become the
basis for careers in science and engineering: automata, intelligent
agents, graphs and data structures, basics of computer science, machine
learning, etc., based on the “Artificial Intelligence: A Modern Approach”
written by Russell Stuart and Norvig (2009). Four studies mentioned the
importance of educating citizens on fundamental AI concepts, and the
impacts of AI technologies on their everyday lives. For example, Rob­
inson (2020) mentioned that the Norwegian policy document, in a
section titled “AI for everyone: Elements of AI” (p. 44) asserts the gov­
ernment will make AI learning courses globally accessible in 2020,
which conceptualizes AI literacy as educating their citizens about the
elements of AI that require no prior knowledge (Robinson, 2020). In
addition, three studies focused on AI learning in specific disciplines (i.e.,
meteorology, medicine and library) to describe how AI can be applied in
vocational training and workplace application (e.g., using healthcare-AI
technologies for delivering prevention, diagnosis, treatment and reha­
bilitation services) (Karaca et al., 2021; Rivero, 2020; Zou et al., 2019).

Table 7
Assessment constructs and tools to evaluate students’ AI learning.
Research
methods

Constructs and tools

Some examples

Sample studies

Quantitative
(13)

Use knowledge tests
to assess students’ AI
cognitive gain and
abilities

Could you order the
major steps for the kmeans clustering
algorithm? (Wan
et al., 2020)
How would you rate
your knowledge
about search
algorithms? (
Kandlhofer et al.,
2016)

Kandlhofer et al.
(2016); Wan et al.
(2020).

3.9. Teacher education
From the review, four articles discussed how learning programs
could strengthen teacher preparation especially for those without prior
knowledge so that they could incorporate AI literacy into school
curricula (Vazhayil et al., 2019; Xu, 2020). Vazhayil et al. (2019)
explored how 34 Indian teachers perceived AI literacy learning after the
workshop (e.g., “How did you find the teaching methods used during the
training?“, “Do you think this workshop will enjoy you the most?“)
(p.74). Teachers need to first update their knowledge of AI concepts that
potentially be introduced in their schools. Then, they design suitable
teaching methods and strategies (e.g., collaborative problem-solving)
and choose age-appropriate learning materials to stimulate students’
interest. They also need to consider various teaching challenges such as
insufficient funding, immature AI curricula, tools and evaluation
methods (Gong et al., 2020), as well as technical concerns that whether
their schools’ internet infrastructure is ready for students to compile
AI-enabled algorithms and applications (Vazhayil et al., 2019).
Apart from updating teachers’ AI knowledge to solve teaching
challenges, educators need to know and use suitable AI-enhanced
technologies such as adaptive learning systems to facilitate their daily

Qualitative
(19)

7

Use perceived
questionnaire to
assess the noncognitive aspects,
including: perceived
ability, confidence in
using AI,
intelligence,
truthfulness,
perceived
understanding,
subjective norms, AI
anxiety, perceived
usefulness of AI, AI
for social good,
attitude toward using
AI, confidence in
learning AI, learning
behavioural
intention, AI
optimsm, relevance,
AI awareness, career
adaptability skills.
Use videos,
documents, pictures,
presentations,
students interactions
with AI agents and
projects to examine
students’ AI cognitive
and non-cognitive
abilities.

Through a follow-up
interview, they
found that children
were able to apply
their new knowledge
of ML to their own
life and to think up
personally
meaningful
applications using
ML (Kaspersen
et al., 2021).
The author
compares how the
three values of trust,
transparency, and
openness are defined
and explored in
Nordic AI policy
documents
(Robinson, 2020).

Chai, Wang, and
Xu (2020); Chai,
Lin, et al. (2020);
Dai et al. (2020);
Druga et al.
(2019);
Gong et al.
(2020); Julie et al.
(2020);
Lin et al. (2021);
Wan et al. (2020).

Burgsteiner et al.
(2016)*; Druga
(2019); Julie et al.
(2020);
Kandlhofer et al.
(2016); Schaper
et al. (2020);
Wan et al. (2020).

D.T.K. Ng et al.

Computers and Education: Artificial Intelligence 2 (2021) 100041

coded in RQ3 since this study aimed to compare how trust, trans­
parency, and openness are defined and explored in AI government policy
documents in different countries.
Quantitative methods: To evaluate K-12 students’ AI literacy, one
important component is to promote their intention to learn and possess
basic knowledge about AI. Thirteen studies used quantitative methods to
assess the knowledge acquisition of K-12 and university students via preand post-knowledge tests (e.g., What are the characteristics of depthfirst search?), and students’ perceived abilities (e.g., How would you
rate your knowledge about search algorithms?) (Kandlhofer et al., 2016;
Wan et al., 2020). Furthermore, studies discussed other quantitative
aspects via surveys to understand students’ perceptions (non-cognitive
aspects) towards AI literacy education such as confidence in using AI,
motivation and AI for societal good.
Qualitative methods: Nineteen researchers collected qualitative data
by taking pictures, field notes during teaching, and interviewing stu­
dents to understand their motivations, expectations and lessons learned.
For example, Druga (2019) recorded students’ interaction with AI
agents through field observations and adopted a three-attribute AI
perception questionnaire to evaluate how 102 children (7–12 years old)
interacted and perceived their AI agents in their lessons. These three
attributes measure whether the agents are smarter, truthful and under­
stand them (e.g., “What do you think of Google Voice, an AI-enabled
agent?“). Children replied that the most fun features were playing
beat-box and music, taking pictures and playing games. Watkins (2020)
collected exhibition feedback from 367 participants to present the most
frequently asked questions in a poster session (e.g., “Will librarians be
able to develop programming with this tool?“) (p.17).

can be considered as knowledge and skills gained which could be
regarded as quantifiable mastery of knowledge regarding AI compo­
nents. Since AI will be more widely taught in K-12 and non-computer
science university programs, it is observed that there will be more
reliable and valid knowledge assessment which can be conveniently
adapted into learning interventions to understand students’ AI knowl­
edge for a summative assessment purpose.
Survey: Surveys are widely used to investigate perceived ability,
affective and non-cognitive learning outcomes (e.g., motivations, atti­
tudes toward AI learning) in educational research. Eleven studies
developed surveys designed quantitative items to understand students’
perceptions of AI, and open-ended questions to collect student selfreport responses. Although surveys were often used to examine stu­
dents’ non-cognitive outcomes, several studies used surveys to elicit
students’ perceived AI understandings. For example, Chai, Wang, and
Xu (2020) and Chai, Lin, et al. (2020) designed a 6-item questionnaire to
understand students’ confidence, perceived relevance of learning AI and
readiness towards AI. The survey was then modified by Lin et al. (2021)
who employed structural equation modeling to validate primary stu­
dents’ motivation for learning AI for the future development of AI
curricula and instruction. It is found that AI literacy is significantly
associated with the aspects including subjective norms, perceived use­
fulness of AI, AI for social good, attitude toward using AI, AI optimism
and confidence in learning AI (Chai, Wang, & Xu, 2020; Lin et al., 2021).
Another study Register & Ko (2020) applied qualitative thematic anal­
ysis of students’ open-ended responses about how machine learning
systems work, as well as other aspects including ML model transparency,
critical thinking and learners’ interests and backgrounds. One advantage
of using surveys is that it consists of convenient data collection from a
large sample size which could produce quantifiable results. However, it
limits students’ rich description from their learning exposure. To fill this
gap, the usage of project portfolio analysis and artefact-based interviews
could be incorporated into knowledge tests and surveys to triangulate
students’ AI learning.
Project portfolio analysis and artefact-based interview: Project
portfolio analysis refers to a purposeful and systematic process of col­
lecting and evaluating various types of students’ learning artefacts such
as products, projects and programs (McMillan, 2013). With students’
project portfolios, researchers and educators can interview students to
examine their AI concepts and practices. Five studies applied project
portfolio analysis with a follow-up interview to examine the attainment
of learning targets. For example, Kaspersen et al. (2021) evaluated
students’ AI models and user interface design through collecting and
labelling data, and building, testing and evaluating models. After ana­
lysing the artefacts in students’ projects, researchers found that children
were able to apply their new knowledge of machine learning (ML) to
their own life and to think up personally meaningful applications using
ML. Another study Watkins (2020) asked participants to create 2D
visualization and related kiosk applications that were demonstrated in
the makerspaces and libraries at universities, and further invited visitors
to perceive their AI applications in Cosmology. Kandlhofer et al. (2021)
studied students’ picture taking, field notes, interaction and project
demonstrations during each teaching unit. Then, they performed
semi-structured interviews and content analysis to examine how stu­
dents foster their AI understandings. However, it is observed that re­
searchers did not generate a grading rubric to indicate the levels of
achievement for each dimension of AI learning performance and
whether a criteria is met. Future research could design rubrics to analyse
students’ AI concepts that could be graded by human raters and/or AI
education systems such as chatbots, expert systems and intelligent tutors
(Zhang & Aslan, 2021).
Through artefact-based interviews, it is useful to understand which
AI components students could understand and use more frequently
through communication and students’ projects. Since AI learning is
novice to K-12 educators, the application of portfolio assessment and
follow-up interviews could capture a holistic view of what extent of

3.11. Tools for assessing AI literacy
To examine AI literacy assessment, researchers and AI educators now
use quantitative and qualitative tools to examine students’ AI literacy
development. To better understand the interplay between cognitive and
non-cognitive constructs of fostering AI literacy, studies began to
explore the changes in attitudes, behaviours and cognitions toward
statistics in different AI educational contexts. Table 7 demonstrates the
assessment constructs and tools to evaluate students’ AI cognitive and
non-cognitive development. To further understand how to examine AI
literacy through quantitative and qualitative tools, we categorized three
major assessment types that have been found in the literature, including
knowledge tests, survey, portfolio assessment and artefact-based in­
terviews. Some studies adopted more than one assessment type to
triangulate the learning outcomes of students’ AI literacy.
Knowledge test: Six studies developed selected or constructedresponse questions such as multiple choice and structured questions
which are evaluated by correctness and completeness for summative
purposes. Kandlhofer et al. (2016) used paper-and-pencil exercises to
assess students’ existing knowledge of AI concepts such as graphs, trees
and data structures as evidence of student AI proficiency. Students’ AI
knowledge acquisition and retention of AI skills was assessed in Lin et al.
(2021), Wan et al. (2020) and Rodríguez-García, Moreno-León,
Román-González, & Robles, 2021 studies via some pre-post knowledge
tests. Lin et al. (2021) administered AI concepts tests to address common
core AI concepts including decision tree, logics system, neural network
and machine learning. Wan et al. (2020) conducted pre-post question­
naires with written answers to questions relating to clustering, similarity
comparison and k-means clustering process whereas Rodríguez-García,
Moreno-León, Román-González, & Robles, 2021 selected and modified
14-item questions from other available tests and online resources, such
as Machine Learning for Kids website and MOOC platforms on AI. Wil­
liams et al. (2019) developed three or four multiple-choice questions on
a tablet or paper to probe what kindergarten children understood about
AI knowledge such as classification and generative AI to triangulate
students’ learning behavior observation in relevant activities.
The usage of this traditional knowledge test suggests that AI literacy
8

D.T.K. Ng et al.

Computers and Education: Artificial Intelligence 2 (2021) 100041

knowledge and skills students need to obtain, and how educators design
and choose their learning materials and tools in their learning design. In
addition, this also encourages educators to use in classrooms and across
platforms to formatively assess students to offer them feedback that is
potentially beneficial to their future AI learning.
With the great potential of using artefact-based interviews, re­
searchers usually employed interviews to support and elaborate on
students’ portfolio assessment by specifying their thinking processes of
using AI skills to solve problems (e.g., how they got started, how the
project evolved, what was important for them to know to make the
project, what problems they encountered throughout the process, and
how they dealt with those problems). Furthermore, students could
reflect on themselves when working on the hands-on projects, such as
what they were most confident of, what they might want to further
improve, and what engaged them. However, the challenges of using
interviews include its high cost and long time spent on interviewing and
coding the data as well as its small distribution to students, which makes
it difficult to be quantified (Tang et al., 2020). Throughout
artefact-based interviews, researchers were able to have detailed dis­
cussions about different AI elements in students’ projects, and to
develop rich descriptions of their development practices.

4. Conclusion
In this review, a variety of definitions of AI literacy was identified.
Most defined AI literacy based on different types of ‘literacies’, which
had recently been applied to define skill sets in other disciplines. Most
researchers advocated that instead of merely knowing how to use AI
applications, learners should learn about the underlying AI concepts for
their future careers and understand the ethical concerns in order to use
AI responsibly.
Since AI literacy is an emerging field that there is a lack of journals
published in this field, several limitations were identified. The keyword
search limited the scope of domain specificity within the AI context
while other subfields of AI like machine learning, neural network, etc.
could potentially be related to this study but were not captured in the
current review. Second, some articles in this review involved in­
terventions and learning programs that were relevant to AI literacy.
However, the articles did not explicitly define the term AI literacy.
Third, a larger pool of studies discussing AI learning and teaching
without mentioning the term “AI literacy” were not included in this
review; however, their interventions could be comparable to AI literacy
instructional design. This suggests that future review could broaden the
scope of search to common AI themes and to capture more literature in
AI learning and teaching.
The existing gaps and needs in the AI literacy research were derived
to bring forth potential areas for future studies. In this review, the ma­
jority of the articles (22) are conference papers while the other eight are
journal publications. Moreover, 19 of the articles used qualitative
research methods and were exploratory research for preliminary studies.
In the near future, it is foreseen that research design will shift to be more
empirical and interventional (e.g., quasi-experiment, design-based
research) with clearly documented treatment and control groups, as well
as varied data analysis procedures (e.g., t-test, one-way analysis of
variance, factor analysis, regression, structural equation modeling).
Furthermore, there is a need to examine the quality of different AI lit­
eracy assessments. Only three studies examine the reliability and val­
idity of scales for AI literacy skills by conducting exploratory and
confirmatory factor analysis (Chai et al., 2020a, 2020b; Dai et al., 2020).
To advance the AI literacy field, priority needs to be placed on proposing
definitive frameworks to guide educators to create lesson designs with
appropriate pedagogies, learning artefacts and assessment criteria. We
hope this review will inspire scholars, educators, and government offi­
cers to begin the discussion on how to define, implement and evaluate AI
literacy in the future.

3.12. RQ 4. what are the ethical concerns in the domain of AI literacy?
As AI plays an important role in day-to-day decision making, misused
or poorly designed AI could cause irreparable harm to humans and the
society (Fourtané, 2020). AI-concerned scientists and engineers like
Elon Musk expound on the horrors that future AI technologies may
wreak on humanity in decades to come (Johnson, 2019). In our review,
Schaper et al. (2020) reflected that international organizations such as
UNICEF and OECD argue for the need of transparency and explainability
in AI to offer meaningful information to understand AI systems, user
interactions and societal impacts (Vincent-Lancrin & Van der Vlies,
2020; UNICEF, 2019). Nineteen studies had mentioned human-centered
considerations, and raised attention to educate citizens to become so­
cially responsible and ethical users (Ahmad, Teredesai, & Eckert, 2020).
Gong et al. (2020) found that students pay little attention to ethical
concerns such as bias in AI and legal responsibility, and intellectual
property. In this regard, researchers began to notice the importance of AI
human-centered concerns such as inclusiveness, fairness, accountability,
transparency, and ethics, instead of merely enhancing students’ AI
abilities and interests (Hagendorff, 2021; Microsoft, 2021). For example,
Lin et al. (2021) designed a middle-school curriculum to develop AI
literacy through combining AI concepts, ethics, awareness and careers.
Their study envisioned that the foundation of future AI industries would
be built on “principles of inclusivity, provide equitable access, include
consideration of multiple stakeholders and potential users, and mini­
mize the potential for bias” (p.191). To summarize, conceptualizing AI
literacy with human-centered considerations is crucial to building a
future inclusive society.
To bring up future responsible citizens who are competent in using AI
in a reliable, trustworthy and fair manner, broadening participation in
AI for everyone and ensuring inclusive AI learning designs are necessary.
Teachers should address the learning needs of under-represented groups
including, but not limited to, gender, ethnic minorities, social-economic
status and cultural background when teaching AI. For example, Druga
(2019) found that low social-economical children tend to have a harder
time advancing AI concepts because they had less experience with
coding and interacting with these technologies in their everyday life.
She proposed a set of guidelines to make AI learning inclusive by
avoiding deceiving technologies, offering ways for children to customize
their machines, and encouraging collaboration to share each other’s
work (Druga, 2019).

4.1. Recommendations for future AI literacy education
The findings of this review present a preliminary overview of
empirical research literature on AI literacy studies in the education field.
This study contributes to addressing the aforementioned research gaps,
and provides directions for future research on AI literacy education
based on the prevalent research questions:
● AI becomes a fundamental skill for everyone, not just for computer
scientists. In addition to reading, writing, arithmetic and digital
skills, we should add AI to every learners’ twenty-first century
technological literacy in work settings and everyday life.
● Inspired by Bloom taxonomy, AI literacy possesses basic compe­
tencies to know and understand, use and apply, as well as evaluate
and create AI. People need to equip themselves cognitively for future
technological challenges in their workplaces. At the same time, it is
important to foster their social responsibility and ethical awareness
to use AI for societal good.
● Students are not only the end users but potentially be problemsolvers to use AI technologies in different scenarios, or even create
possible AI-driven hardware and software solutions to make our
society a better place to live in.
9

Computers and Education: Artificial Intelligence 2 (2021) 100041

D.T.K. Ng et al.

● AI literacy combines the ideas of data science, computational
thinking and multi-disciplinary knowledge to interplay AI literacy
and AI thinking.
● To facilitate educators’ teaching, the technological, pedagogical and
content knowledge framework needs to be considered to provide a
map for understanding how to integrate AI literacy into classrooms
effectively. Age-appropriate learning artefacts and curricula need to
be designed to scaffold K-12 students’ AI conceptual understandings
and stimulate their motivation and interest in learning AI.
● Educators should update their AI knowledge to solve teaching
challenges such as knowing and using suitable AI-enhanced tech­
nologies such as adaptive learning systems that facilitate their daily
teaching practice and management, and promote personalized
learning to understand students’ learning progress and needs.
● Future researcher and educators will develop pedagogical strategies
(e.g., collaborative project-based learning, gamification) and theo­
retical models (e.g., self-determination theory, constructionism) to
increase students’ motivation and engagement, promote interaction
and collaboration, enhance motivation and attitudes, and develop
numerous learning skills in the context of AI literacy.
● Future researchers and educators will develop quantitative and
qualitative assessments to examine students’ learning performance
via post-knowledge tests, self-perceived surveys, learners’ artefacts,
projects and conversations.
● Human-centered considerations are important to raise attention to
educate citizens to become socially responsible and ethical users
such as inclusiveness, fairness, accountability, transparency, and
ethics, instead of merely enhancing students’ AI abilities and
interests.

Fourtané, S. (2020, August). In Ethics of AI: Benefits and risks of artificial intelligence
systems. Interesting engineering. Retrieved from https://interestingengineering.com/et
hics-of-ai-benefits-and-risks-of-artificial-intelligence-systems.
Ghallab, M. (2019). Responsible AI: Requirements and challenges. AI Perspectives, 1(1),
1–7.
Gong, X., Tang, Y., Liu, X., Jing, S., Cui, W., Liang, J., & Wang, F. Y. (2020, October). K-9
artificial intelligence education in qingdao: Issues, challenges and suggestions. In
IEEE international conference on networking, sensing and control (ICNSC) (pp. 1–6).
IEEE.
Graham, C. R. (2011). Theoretical considerations for understanding technological
pedagogical content knowledge (TPACK). Computers & Education, 57(3), 1953–1960.
Griffin, P., & Care, E. (Eds.). (2014). Assessment and teaching of 21st century skills: Methods
and approach. Springer.
Hagendorff, T. (2020). The ethics of AI ethics: An evaluation of guidelines. Minds and
Machines, 30(1), 99–120.
Han, X., Hu, F., Xiong, G., Liu, X., Gong, X., Niu, X., & Wang, X. (2018). Design of AI+
curriculum for primary and secondary schools in qingdao. In In Chinese automation
congress (CAC) (pp. 4135–4140). IEEE.
How, M. L., & Hung, W. L. D. (2019). Educing AI-thinking in science, technology,
engineering, arts, and mathematics (STEAM) education. Education Sciences, 9(3),
184.
Huitt, W. (2011). Bloom et al.’s taxonomy of the cognitive domain (Vol. 22). Educational
psychology interactive.
Johnson, K. (2010, November). AI ethics is all about power. Venturebeat Insider - the
Machine Making Sense of AI. Retrieved from https://venturebeat.com/2019/11/11/
ai-ethics-is-all-about-power/.
Julie, H., Alyson, H., & Anne-Sophie, C. (2020, October). Designing digital literacy
activities: An interdisciplinary and collaborative approach. In 2020 IEEE frontiers in
education conference (FIE) (pp. 1–5). IEEE.
Kandlhofer, M., Steinbauer, G., Hirschmugl-Gaisch, S., & Huber, P. (2016, October).
Artificial intelligence and computer science in education: From kindergarten to
university. In IEEE Frontiers in education conference (FIE) (pp. 1–9). IEEE.
Karaca, O., Çalışkan, S. A., & Demir, K. (2021). Medical artificial intelligence readiness
scale for medical students (MAIRS-MS)–development, validity and reliability study.
BMC Medical Education, 21(1), 1–9.
Kaspersen, M. H., Bilstrup, K. E. K., & Petersen, M. G. (2021, February). The machine
learning machine: A tangible user interface for teaching machine learning. In
Proceedings of the fifteenth international conference on tangible, embedded, and embodied
interaction (pp. 1–12).
Kim, S., Jang, Y., Choi, S., Kim, W., Jung, H., Kim, S., & Kim, H. (2021). Analyzing teacher
competency with TPACK for K-12 AI education. KI-Künstliche Intelligenz.
Koehler, M. J., Mishra, P., & Cain, W. (2013). What is technological pedagogical content
knowledge (TPACK)? Journal of Education, 193(3), 13–19.
Kong, S. C., Cheung, W. M. Y., & Zhang, G. (2021). Evaluation of an artificial intelligence
literacy course for university students with diverse study backgrounds. In Computers
and education. Artificial Intelligence, Article 100026.
Larson, L. C., & Miller, T. N. (2011). 21st century skills: Prepare students for the future.
Kappa Delta Pi Record, 47(3), 121–123.
Leahy, D., & Dolan, D. (2010, September). Digital literacy: A vital competence for 2010?.
In IFIP international conference on key competencies in the knowledge society (pp.
210–221). Berlin, Heidelberg: Springer.
Leander, K. M., & Burriss, S. K. (2020). Critical literacy for a posthuman world: When
people read, and become, with machines. British Journal of Educational Technology,
51(4), 1262–1276.
Lin, P. Y., Chai, C. S., Jong, M. S. Y., Dai, Y., Guo, Y., & Qin, J. (2021). Modeling the
structural relationship among primary students’ motivation to learn artificial
intelligence. Computers & Education: Artificial Intelligence, 2, Article 100006.
Long, D., Jacob, M., & Magerko, B. (2019). Designing co-creative AI for public spaces. In
Proceedings of the 2019 on creativity and cognition (pp. 271–284).
Long, D., & Magerko, B. (2020, April). What is AI literacy? Competencies and design
considerations. In Proceedings of the 2020 CHI conference on human factors in
computing systems (pp. 1–16).
Manyika, J., Lund, S., Chui, M., Bughin, J., Woetzel, J., Batra, P., Ko, R., & Sanghvi, S.
(2017, December). Jobs lost, jobs gained: Workforce transitions in a time of
automation. McKinsey global institute. Retrieved from https://www.mckinsey.
com/~/media/McKinsey/Industries/Public%20and%20Social%20Sector/Our%20I
nsights/What%20the%20future%20of%20work%20will%20mean%20for%20jobs%
20skills%20and%20wages/MGI-Jobs-Lost-Jobs-Gained-Report-December-6-2017.
pdf.
McCarthy, J. (2007). From here to human-level AI. Artificial Intelligence, 171(18),
1174–1182.
McMillan, J. H. (2013). Classroom assessment: Principles and practice for effective instruction
(6th ed.). Boston: Pearson/Allyn and Bacon.
Microsoft. (2021). Fate: Fairness, accountability, transparency, and ethics in AI.
Retrieved from https://www.microsoft.com/en-us/research/theme/fate/.
Mongeon, P., & Paul-Hus, A. (2016). The journal coverage of web of science and Scopus:
A comparative analysis. Scientometrics, 106(1), 213–228.
Ng, T. K. (2021). New interpretation of extracurricular activities via social networking
sites: A case study of artificial intelligence learning at a secondary school in Hong
Kong. Journal of Education and Training Studies, 9(1), 49–60.
Ng, T. K., & Chu, K. W. (2021). Motivating students to learn AI through social networking
sites: A case study in Hong Kong. Online Learning, 25(1), 195–208.
Ng, T. K., Leung, J. K. L., Chu, K. W. S., & Qiao, M. S. (2021). AI literacy: Definition,
teaching, evaluation and ethical issues. Proceedings of the Association for Information
Science and Technology, 58(1), 504–509.

Declaration of competing interest
The authors declare that they have no known competing financial
interests or personal relationships that could have appeared to influence
the work reported in this paper.
References
Ahmad, M. A., Teredesai, A., & Eckert, C. (2020, January). Fairness, accountability,
transparency in AI at scale: Lessons from national programs. In Proceedings of the
2020 ACM conference on fairness, accountability, and transparency, 690-690.
Bawden, D. (2008). Origins and concepts of digital literacy. Digital Literacies: Concepts,
Policies and Practices, 30, 17–32.
Bell, S. (2010). Project-based learning for the 21st century: Skills for the future. The
clearing House, 83(2), 39–43.
Bloom, B. S. (1956). Taxonomy of educational objectives (Vol. 1, pp. 20–24). New York:
McKay: Cognitive domain.
Brundage, M., Avin, S., Clark, J., Toner, H., Eckersley, P., Garfinkel, B., & Amodei, D.
(2018). The malicious use of artificial intelligence: Forecasting, prevention, and
mitigation. University of Oxford. arXiv preprint arXiv:1802.07228.
Burgsteiner, H., Kandlhofer, M., & Steinbauer, G. (2016, March). Irobot: Teaching the
basics of artificial intelligence in high schools. In Proceeding of the AAAI conference on
artificial intelligence, 30(1).
Cavalcanti, A. P., Diego, A., Carvalho, R., Freitas, F., Tsai, Y. S., Gašević, D., &
Mello, R. F. (2021). Automatic feedback in online learning environments: A systematic
literature review. Computers and Education: Artificial Intelligence, Article 100027.
Chai, C. S., Wang, X., & Xu, C. (2020a). An extended theory of planned behavior for the
modelling of Chinese secondary school students’ intention to learn Artificial
Intelligence. Mathematics, 8(11), 2089.
Chai, C. S., Lin, P. Y., Jong, M. S. Y., Dai, Y., Chiu, T. K., & Huang, B. (2020, August).
Factors influencing students’ behavioral intention to continue artificial intelligence
learning. In 2020 international symposium on educational technology (pp. 147–150).
IEEE.
Dai, Y., Chai, C. S., Lin, P. Y., Jong, M. S. Y., Guo, Y., & Qin, J. (2020). Promoting
students’ well-being by developing their readiness for the artificial intelligence age.
Sustainability, 12(16), 6597.
Davenport, T. H., & Ronanki, R. (2018). Artificial intelligence for the real world. Harvard
Business Review, 96(1), 108–116.
Dignum, V. (2019). Responsible artificial intelligence: How to develop and use AI in a
responsible way. Springer Nature.
Druga, S., Vu, S. T., Likhith, E., & Qiu, T. (2019). Inclusive AI literacy for kids around the
world. In Proceedings of FabLearn 2019 (pp. 104–111). ACM.

10

D.T.K. Ng et al.

Computers and Education: Artificial Intelligence 2 (2021) 100041
Touretzky, D., Gardner-McCune, C., Martin, F., & Seehorn, D. (2019, July). Envisioning
AI for K-12: What should every child know about AI?. In Proceedings of the AAAI
conference on artificial intelligence (Vol. 33, pp. 9795–9799). No. 01.
United Nations Children’s Fund (UNICEF). (2019). Workshop report: AI and child rights
policy. Retrieved from https://www.unicef.org/globalinsight/media/661/file.
Vazhayil, A., Shetty, R., Bhavani, R. R., & Akshay, N. (2019, December). Focusing on
teacher education to introduce ai in schools: Perspectives and illustrative findings. In
In 2019 IEEE tenth international conference on technology for education (T4E) (pp.
71–77). IEEE.
Vincent-Lancrin, S., & Van der Vlies, R. (2020). Trustworthy artificial intelligence (AI) in
education: Promises and challenges. OECD.
Wan, X., Zhou, X., Ye, Z., Mortensen, C. K., & Bai, Z. (2020, June). SmileyCluster:
supporting accessible machine learning in K-12 scientific discovery. In Proceedings of
the Interaction Design and Children Conference (pp. 23–35).
Wang, P. (2019). On defining artificial intelligence. Journal of Artificial General
Intelligence, 10(2), 1–37.
Watkins, T. (2020). Cosmology of artificial intelligence project: Libraries, makerspaces,
community and AI literacy. AI Matters, 5(4), 14–17.
Williams, R., Park, H. W., & Breazeal, C. (2019, May). A is for artificial intelligence: The
impact of artificial intelligence activities on young children’s perceptions of robots.
In Proceedings of the 2019 CHI conference on human factors in computing systems (pp.
1–11).
Wong, G. K., Ma, X., Dillenbourg, P., & Huan, J. (2020). Broadening artificial intelligence
education in K-12: Where to start? ACM Inroads, 11(1), 20–29.
Xu, L. (2020, December). The dilemma and countermeasures of AI in educational
application. In In 2020 4th international conference on computer science and artificial
intelligence (pp. 289–294). ACM.
Zawacki-Richter, O., Marín, V. I., Bond, M., & Gouverneur, F. (2019). Systematic review
of research on artificial intelligence applications in higher education – where are the
educators? International of Journal Education Technology Higher Education, 16, 39.
https://doi.org/10.1186/s41239-019-0171-0
Zou, L., Wang, Q., & Zhao, P. (2019, October). A preliminary study on the application of
artificial intelligence technology in meteorological education and training. In IEEE/
WIC/ACM international conference on web intelligence-companion volume (pp.
148–153). ACM.

Pegrum, M., Dudeney, G., & Hockly, N. (2018). Digital literacies revisited. European
Journal of Applied Linguistics and TEFL, 7(2), 3–24.
Register, Y., & Ko, A. J. (2020, August). Learning machine learning with personal data
helps stakeholders ground advocacy arguments in model mechanics. In In
Proceedings of the 2020 ACM conference on international computing education research
(pp. 67–78). ACM.
Rivero, E. (2020). Library and educational use cases. Library Technology Reports, 56(4),
14.
Robinson, S. C. (2020). Trust, transparency, and openness: How inclusion of cultural
values shapes Nordic national public policy strategies for artificial intelligence (AI).
Technology in Society, 63, 101421.
Rodríguez-García, J. D., Moreno-León, J., Román-González, M., & Robles, G. (2020,
October). Introducing artificial intelligence fundamentals with LearningML:
Artificial intelligence made easy. In In Eighth international conference on technological
ecosystems for enhancing multiculturality (pp. 18–20). ACM.
Rodríguez-García, J. D., Moreno-León, J., Román-González, M., & Robles, G. (2021,
March). Evaluation of an online intervention to teach artificial intelligence with
LearningML to 10-16-year-old students. In Proceedings of the 52nd ACM technical
symposium on computer science education (pp. 177–183). ACM.
Russell Stuart, J., & Norvig, P. (2009). Artificial intelligence: A modern approach. Prentice
Hall.
Schaper, M. M., Malinverni, L., & Valero, C. (2020, October). Robot presidents: Who
should rule the world? Teaching critical thinking in AI through reflections upon food
traditions. In Proceedings of the 11th nordic conference on human-computer interaction:
Shaping experiences (pp. 1–4). Shaping Society.
Sharma, A. (2019, November). Entrepreneurship and role of AI. In Proceedings of the 2019
2nd international conference on signal processing and machine learning (pp. 122–126).
ACM.
Steinbauer, G., Kandlhofer, M., Chklovski, T., Heintz, F., & Koenig, S. (2021).
A differentiated discussion about AI education K-12 (pp. 1–7). KI-Künstliche Intelligenz.
Tang, X., Yin, Y., Lin, Q., Hadad, R., & Zhai, X. (2020). Assessing computational thinking:
A systematic review of empirical studies. Computers & Education, 148, Article
103798.

11

