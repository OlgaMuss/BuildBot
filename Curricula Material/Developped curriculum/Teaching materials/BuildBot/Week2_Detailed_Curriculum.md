# Week 2: AI Literacy + Continue Assembling Marty

## üìã Overview
**Duration:** 2 hours 15 minutes  
**Theme:** Understanding AI and Machine Learning  
**Storyline Step:** Continue assembling Marty robot components  
**Key Narrative:** "Teaching Marty to Think - Understanding How AI Works"

---

## üéØ Learning Objectives

### Primary Goals
- Understand artificial intelligence and machine learning concepts
- Learn about different types of machine learning (supervised, unsupervised, reinforcement)
- Explore Large Language Models (LLMs) and their capabilities
- **Storyline Step 1 (continued):** Continue assembling Marty robot components

### Secondary Goals
- Connect AI concepts to Marty's future capabilities
- Develop critical thinking about AI applications
- Build foundation for programming Marty in future weeks

---

## üìÖ Detailed Agenda

### 7:20 - 7:35 (15 minutes) - Intro to AI
**Slide Storyline:** "What is Artificial Intelligence?"

#### Slide 1: Artificial Intelligence Definition
**Visual Elements:**
- AI concept visualization with brain and computer icons
- AI vs Not AI comparison
- Examples of technology with and without AI

**Teaching Points:**
- **Definition:** "Artificial intelligence (AI) is a large domain in software engineering and is 'defined as machine intelligence or intelligence demonstrated by machines'" (Belipetriv et al. 2020)
- **AI vs Not AI:**
  - **Not AI:** command ‚Üí action (simple programming)
  - **AI:** learns from data and makes decisions
- **Daily Examples:** Phone assistants, recommendation systems, image recognition
- **Connection to Marty:** "Marty will use AI to understand and respond to you"

**Discussion Question:** "What are examples of technology not using AI?"
**Examples:** television, regular cars, remote controlled toy cars, regular video games, etc.

#### Slide 2: Machine Learning Definition
**Visual Elements:**
- Machine learning concept diagram
- Types of learning visualization
- Ways and outcomes of learning

**Teaching Points:**
- **Definition:** "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of algorithms that can learn from data and generalise to new data, and thus perform tasks without the use of explicit rules."
- **Types of Learning (on what data):**
  - **With labels:** supervised learning
  - **Without labels:** unsupervised learning
  - **By trial and error with rewards:** reinforcement learning
- **Ways of Learning (with which model):**
  - Classic, Non-neural algorithms
  - Neural networks
- **Outcomes of Learning (what can it do):**
  - Classification / Prediction - labels or projects
  - Generation (GenAI) - creates
  - Pursue of a goal (AI agents) - decides and acts

**Source:** wikipedia

### 7:35 - 7:55 (20 minutes) - Activity 1: Machine Learning Types Game
**Slide Storyline:** "Learning How Machines Learn"

#### Slide 3: Supervised Learning Examples
**Visual Elements:**
- Supervised learning examples with icons
- Real-world application scenarios
- Connection to daily technology use

**Teaching Points:**
- **Supervised learning (discriminative)** ‚Äî uses classified/labeled data
- **Examples:**
  - **Face recognition:** When your phone automatically suggests tagging friends in photos, it uses supervised learning trained on photos you've previously labeled with people's names.
  - **Music recommendation:** When Spotify suggests songs you might like, it uses supervised learning trained on data like "User A liked songs X, Y, Z" to predict what new songs you'll enjoy.
  - **Content filtering:** Apps, such as WhatsApp, learn to identify spam messages by training on thousands of messages that were labeled as "spam" or "not spam" by users and moderators.

#### Slide 4: Unsupervised Learning Examples
**Visual Elements:**
- Unsupervised learning examples with icons
- Pattern discovery visualization
- Real-world application scenarios

**Teaching Points:**
- **Unsupervised learning (generative)** ‚Äî uses unclassified / unlabeled data
- **Examples:**
  - **Content recommendation:** TikTok groups users with similar viewing patterns together without being told what the groups should be. It discovers that some users love cooking videos, others prefer dance content, and others watch gaming clips - all without anyone labeling these categories beforehand.
  - **Shopping recommendation:** Amazon's "Customers who bought this also bought" discovers hidden patterns in purchasing behavior. It might find that people who buy certain gaming keyboards also tend to buy specific mouse pads, without anyone teaching it these relationships.
  - **Automatic photo albums:** When Google Photos, or Apple Photos create albums like "Trip to Berlin" or "School friends," they are finding patterns in when and where photos were taken, and who appears in them, without being told these are meaningful groups.

#### Slide 5: Reinforcement Learning Examples
**Visual Elements:**
- Reinforcement learning examples with icons
- Trial and error visualization
- Real-world application scenarios

**Teaching Points:**
- **Reinforcement learning** ‚Äî No data required, learns from the experience, etc.
- **Examples:**
  - **Video Game AI players:** Minecraft's AI companions use trial and error AI models getting rewards for successfully mining resources or building structures, and penalties for falling into lava.
  - **Recommendation timing:** Video recommendation timing algorithms such as on YouTube, learn when to show notifications by testing different times and seeing when it is most likely to be clicked on. If you engage more at 7 PM, it gets rewarded and learns to notify you then.
  - **Lesson difficulty adjustment:** Learning apps, such as Duolingo, learn to adjust how hard your German or English lessons should be by seeing if you succeed or struggle, constantly fine-tuning to keep you motivated but challenged.

#### Slide 6: Machine Learning Types Game
**Visual Elements:**
- Game setup instructions
- Cards activity visualization
- Hands-on learning elements

**Teaching Points:**
- **Let's play an unplugged game: Machine Learning Types Game**
- **Cards activity for hands-on learning**
- **Game Objective:** Students become "human machine learning algorithms"
- **Hands-on Experience:** Students experience how machines learn from data
- **Connection to Marty:** "This is how Marty will learn to recognize patterns"

**Activity Setup:**
- Distribute Human Machine Learning Lab materials
- Explain game rules and objectives
- Form groups of 3-4 students
- Begin supervised learning simulation

### 7:55 - 8:15 (20 minutes) - Intro to AI Chatbots
**Slide Storyline:** "Meet the AI That Will Help Marty Communicate"

#### Slide 7: AI Chatbots Introduction
**Visual Elements:**
- AI chatbot interface examples
- User interaction visualization
- Hand-raising poll element

**Teaching Points:**
- **Discussion Question:** "How many of you have already used an AI chatbot? (raise your hand)"
- **AI Chatbots, such as chatGPT are Large Language Models, considered Generative AI**
- **Connection to Marty:** "LLMs will help Marty understand and respond to your questions"

#### Slide 8: Large Language Models Definition
**Visual Elements:**
- LLM architecture diagram
- Training process visualization
- Cost and complexity indicators

**Teaching Points:**
- **Definition:** "A large language model (LLM) is a language model trained with self-supervised machine learning on a vast amount of text, designed for natural language processing tasks, especially language generation. They are also called Foundational Models and are costly to develop."
- **In simple words:** A program that can converse with humans.
- **Source:** wikipedia
- **Training Cost:** Expensive to develop, requiring massive resources

**Discussion Question:** "Can you guess which type, way and outcomes LLMs (large language models) use?"

#### Slide 9: LLM Learning Process
**Visual Elements:**
- Three-step learning process diagram
- Learning types visualization
- Neural network representation

**Teaching Points:**
- **LLMs use all 3 types of learning in 3 steps:**
- **Types of learning:**
  - With labels: supervised learning
  - Without labels: unsupervised learning
  - By trial and error with rewards: reinforcement learning
- **Ways of learning:**
  - Deep neural networks
- **Outcomes of learning:**
  - Generation using prediction, and also used as an agent

#### Slide 10: Creating LLMs - Step 1: Unsupervised Learning
**Visual Elements:**
- Reading process visualization
- Pattern recognition examples
- Child metaphor illustration

**Teaching Points:**
- **Step 1: Unsupervised Learning - "Reading a lot"**
- **What happens:** The AI reads millions of books, websites, and articles without anyone telling it what's important. It just learns patterns in language - like which words usually come after others.
- **The metaphor:** Imagine a child who secretly listens to every conversation in their house, at school, and on TV for years. They start noticing patterns: "When people say 'Good morning,' others usually respond with 'Good morning' back" or "The word 'because' is usually followed by an explanation."
- **Real example:** The AI learns that after "The capital of Germany is..." the word "Berlin" usually comes next, just from seeing this pattern thousands of times in different texts.
- **Note:** Large language models use text data, but the same ideas are being applied to images, sensor data, audio data, etc. Those are not considered Large Language Models.

#### Slide 11: Creating LLMs - Step 2: Supervised Learning
**Visual Elements:**
- Tutoring metaphor visualization
- Good answer examples
- Human guidance process

**Teaching Points:**
- **Step 2: Supervised Learning - "Learning what is a 'good' answer"**
- **What happens:** Now humans give the AI specific examples of good answers to questions. They show it: "When someone asks this question, HERE is a good response."
- **The metaphor:** It's like the child now has a tutor who says: "When someone asks for help with homework, don't just copy what you heard people say - actually try to help them understand the math problem."
- **Real example:** Humans show the AI thousands of examples like:
  Question: "Explain photosynthesis" 
  Good Answer: "Photosynthesis is how plants use sunlight to make food..."

#### Slide 12: Creating LLMs - Step 3: Reinforcement Learning
**Visual Elements:**
- Feedback process visualization
- Good vs bad response examples
- Learning from feedback

**Teaching Points:**
- **Step 3: Reinforcement Learning - "Learning to provide a 'good' answer"**
- **What happens:** Humans rate the AI's responses as "good" or "bad." The AI learns to avoid responses that humans dislike and favor ones they prefer.
- **The metaphor:** Like getting feedback from friends - if they always groan when you tell certain jokes, you learn to stop telling those jokes. If they laugh at others, you tell more of those.
- **Real example:** If the AI gives a rude response, humans mark it as "bad." If it gives a helpful, polite response, they mark it as "good." The AI learns to be more like the "good" examples.

### 8:15 - 8:30 (15 minutes) - Activity 2: Soekia and Classification vs Generation Worksheet
**Slide Storyline:** "Hands-on Experience with AI"

#### Slide 13: LLM Summary
**Visual Elements:**
- Three-step summary diagram
- LLM development process
- Mathematical model representation

**Teaching Points:**
- **These 3 steps are involved in the building of Large Language Models**
- **Step 1: Unsupervised Learning - "Reading a lot"**
  Real example: The AI learns that after "The capital of Germany is..." the word "Berlin" usually comes next, just from seeing this pattern thousands of times in different texts.
- **Step 2: Supervised Learning - "Learning what is a 'good' answer"**
  Real example: Humans show the AI thousands of examples like: Question: "Explain photosynthesis" Answer: "Photosynthesis is how plants use sunlight to make food..." ‚Üí Good
- **Step 3: Reinforcement Learning - "Learning to provide a 'good' answer"**
  Real example: If the AI gives a rude response, humans mark it as "bad." If it gives a helpful, polite response, they mark it as "good." The AI learns to be more like the "good" examples.
- **Large Language Model (LLM)** that is a precise mathematical model with its parameters, also called weights

#### Slide 14: Major Large Language Models
**Visual Elements:**
- Company logos and model names
- Geographic distribution
- Model comparison chart

**Teaching Points:**
- **Major Large Language Models (LLMs):**
  - **OpenAI models (US):** ex: GPT-5, GPT-4o
  - **Google models (US):** ex: Gemini 2.5 Pro, etc
  - **Anthropic models (US):** ex: Claude 3.7 Sonnet
  - **Meta models (US):** ex: Llama 4 series
  - **DeepSeek models (China)**
  - **Mistral (France)**
  - **xAI's Grok (US)**
  - **Apertus (Switzerland)**
  - **and others...**

**Discussion Question:** "Which ones have you tried?"

#### Slide 15: How AI Chatbots Work
**Visual Elements:**
- Chatbot interaction flow
- Memory file system
- Learning illusion explanation

**Teaching Points:**
- **AI chatbots use LLMs models**
- When we interact with an AI chatbot (send them text, called prompts), the underlying model does not change (the weights are unchanged), therefore technically does not learn.
- **However, software using LLMs can create memory files, which are added to prompts creating an illusion of learning.**
- **LLMs can apply their "knowledge" (patterns learned in the previous steps) to new data, like to analysing a new text and detecting its patterns, and by doing so, creating new knowledge for us to learn.**
- **Often our conversations are recorded and used as input or test data for new models (for ex. conversations with GPT-4 used to create GPT-5)**

#### Slide 16: Soekia GPT Activity
**Visual Elements:**
- Soekia GPT interface screenshot
- Activity instructions
- Interactive elements

**Teaching Points:**
- **Let's try a simple version of an LLM**
- **Activity Steps:**
  1. Go to the Soekia GPT website.
  2. Ask it to: "Write me a fairy tale".
  3. Pause the generation after a few words/sentences and click at the bottom on "select yourself". You can now click on the next word yourself (selected from the most likely matches of the model). Combine self-select/auto-generate to create a fairy tale.
  4. Click on "Look inside" in the top right corner to better understand how this works. Explore.
  5. Click on the trash can under the created story to start over again. Ask another question, e.g: Explain me the Pythagorean theorem. How well does Soekia do?
- **Questions and Discussion after 10 minutes**

#### Slide 17: Classifier or Generator Activity
**Visual Elements:**
- Activity worksheet
- Classification vs generation examples
- Answer guide

**Teaching Points:**
- **Classifier or generator activity (5 minutes)**
- **Answers guide provided**
- **Learning Objective:** Understanding classification vs generation tasks
- **Worksheet Activities:**
  - Test classification capabilities with various prompts
  - Test generation capabilities with creative tasks
  - Compare and contrast the two types of AI responses
  - Reflect on strengths and limitations of each

### 8:30 - 8:45 (15 minutes) - Break
**Slide Storyline:** "Reflecting on AI Learning"

#### Slide 18: LLM Summary Diagram
**Visual Elements:**
- Summary diagram of LLM development
- Process flow visualization
- Key concepts overview

**Teaching Points:**
- **In summary:**
- **Step 1: Unsupervised Learning "Reading a lot"** ‚Üí first version of an LLM
- **Step 2: Supervised Learning "Learning what is a 'good' answer"** ‚Üí second version of an LLM
- **Step 3: Reinforcement Learning "Learning to provide a 'good' answer"** ‚Üí final LLM
- **A lot of text** ‚Üí **AI chatbot**

**Reflection Questions:**
1. What surprised you most about how AI works?
2. How do you think Marty will use these AI concepts?
3. What questions do you have about AI and machine learning?

### 8:45 - 9:30 (45 minutes) - Building Marty - Continue Assembly
**Slide Storyline:** "Building Marty with AI Understanding"

#### Slide 19: Building Activity
**Visual Elements:**
- Screenshot of building guide
- Marty robot image
- Building progress indicators

**Teaching Points:**
- **Let's start building**
- **Review Progress:** Check legs assembly completion
- **Today's Goals:** Continue with next assembly components
- **AI Connection:** "As we build Marty, think about how these physical parts will work with AI"
- **Collaboration:** Continue working in pairs, helping each other

**Building Activity:**
- Distribute robot kits and tools
- Guide students through next assembly steps
- Monitor progress and provide assistance
- Encourage discussion about AI applications while building

### 9:30 - 9:35 (5 minutes) - Assessment and Reflection
**Slide Storyline:** "Connecting AI Concepts to Marty"

#### Slide 20: Annexes
**Visual Elements:**
- Additional materials section
- Learning objectives checklist
- Concept connections diagram

**Teaching Points:**
- **AI Understanding:** Machine learning types, LLM capabilities
- **Hands-on Experience:** Human machine learning game, Soekia interaction
- **Building Progress:** Continued Marty assembly
- **Concept Integration:** Connecting AI theory to practical application

**Reflection Questions:**
1. How do you think Marty will use machine learning?
2. What type of AI tasks do you think Marty will be best at?
3. What are you most excited about for next week?

---

## üé® Slide Design Storyline

### Visual Theme: "AI in Action"
- **Color Palette:** Purple (AI), Blue (technology), Green (learning)
- **Typography:** Modern, tech-inspired, clear hierarchy
- **Icons:** AI, machine learning, and technology symbols
- **Layout:** Clean, focused on key concepts with interactive elements

### Interactive Elements
- **Hands-on Activities:** Human machine learning game, Soekia interaction
- **Discussion Prompts:** Built into each slide
- **Visual Comparisons:** AI types, task categories
- **Progress Tracking:** Building and learning progress

### Accessibility Features
- **Clear Contrast:** High contrast for readability
- **Readable Fonts:** Large, clear typography
- **Visual Hierarchy:** Important concepts emphasized
- **Multilingual Support:** English and German versions

---

## üìö Teaching Materials

### Required Resources
- **Week 2 Teaching Materials:** [Canva Design Link](https://www.canva.com/design/DAGygIveXRg/YE7B9XMih-8w_Sh-r9VVCg/edit)
- **The Human Machine Learning Lab - Guide:** [Complete Activity Guide](file:///Users/olga/Olga's%20workspace/ETHZ%20SBS/Marty%20project/Deployment/Material/Curricula%20Material/Developped%20curriculum/Teaching%20materials/The%20Human%20Machine%20Learning%20Lab%20-%20Guide)
- **The Human Machine Learning Lab - Cards:** [Complete Card Sets](file:///Users/olga/Olga's%20workspace/ETHZ%20SBS/Marty%20project/Deployment/Material/Curricula%20Material/Developped%20curriculum/Teaching%20materials/The%20Human%20Machine%20Learning%20Lab%20-%20cards)

### Hardware Requirements
- Marty robot kits (continuing assembly)
- Building tools and materials
- Computers/tablets for Soekia access

### Software Requirements
- Soekia GPT website access
- Internet connection for LLM platforms
- Human Machine Learning Lab materials

---

## üìä Assessment Strategy

### Weekly Assessment (T2) - 5 minutes
- **AI Concept Understanding:** Machine learning types, LLM capabilities
- **Hands-on Experience:** Reflection on activities
- **Building Progress:** Assembly completion evaluation
- **Concept Integration:** Connection between AI theory and practical application

### Activity Assessments
- **Human Machine Learning Game:** Participation and understanding
- **Soekia Interaction:** Appropriate use and learning
- **Building Progress:** Continued assembly success
- **Discussion Participation:** Engagement and understanding

---

## üéØ Success Indicators

### Student Engagement
- Active participation in hands-on activities
- Thoughtful questions about AI concepts
- Successful completion of activities
- Enthusiastic building progress

### Learning Outcomes
- Clear understanding of AI and machine learning concepts
- Ability to distinguish between learning types
- Basic knowledge of LLM capabilities
- Successful continued assembly

### Teacher Observations
- Smooth activity transitions
- Effective hands-on learning
- Student collaboration and support
- Clear concept understanding

---

## üîÑ Differentiation Strategies

### For Advanced Students
- **Extension Questions:** Deeper analysis of AI applications
- **Research Opportunities:** Explore additional AI examples
- **Leadership Roles:** Help peers with activities

### For Struggling Students
- **Additional Support:** Individual assistance during activities
- **Simplified Explanations:** Break down complex concepts
- **Peer Collaboration:** Pair with supportive classmates

### For Different Learning Styles
- **Visual Learners:** Rich diagrams and visualizations
- **Kinesthetic Learners:** Hands-on activities and building
- **Auditory Learners:** Discussion and verbal explanations

---

## üìù Notes and Observations

### Implementation Tips
- **Preparation:** Set up activity materials in advance
- **Technology:** Ensure reliable internet for Soekia access
- **Engagement:** Use hands-on activities to maintain attention
- **Flexibility:** Adjust timing based on activity progress

### Common Challenges
- **Concept Complexity:** AI concepts may be challenging for some students
- **Technology Issues:** Internet connectivity or platform access
- **Activity Management:** Coordinating multiple hands-on activities
- **Time Management:** Balancing activities with building time

### Success Factors
- **Clear Objectives:** Well-defined learning goals
- **Hands-on Learning:** Immediate practical application
- **Collaborative Environment:** Peer support and teamwork
- **Progressive Complexity:** Building on previous week's learning

---

*This detailed curriculum provides comprehensive guidance for implementing Week 2 of the Marty AI Literacy Curriculum. The integration of AI concepts with hands-on activities creates engagement while building essential knowledge for future programming.*
